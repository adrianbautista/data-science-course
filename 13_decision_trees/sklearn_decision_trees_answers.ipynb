{
 "metadata": {
  "name": "",
  "signature": "sha256:ba7884319c6f2e59aa28648a9fdfb018b27b4b4efe09f708c38b3deb3ceb291f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Explaining Titanic Hypothesis with Decision Trees\n",
      "*From book \"Learning scikit-learn: machine learning in Python\"*<br />\n",
      "Modified to use pandas"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Preprocessing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, we must load the dataset. We assume it is located in the data/titanic.csv file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "titanic = pd.read_csv('data/titanic.csv')\n",
      "titanic_y = titanic.survived\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#TEMP\n",
      "titanic.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>survived</th>\n",
        "      <th>pclass</th>\n",
        "      <th>name</th>\n",
        "      <th>sex</th>\n",
        "      <th>age</th>\n",
        "      <th>sibsp</th>\n",
        "      <th>parch</th>\n",
        "      <th>ticket</th>\n",
        "      <th>fare</th>\n",
        "      <th>cabin</th>\n",
        "      <th>embarked</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                           Braund, Mr. Owen Harris</td>\n",
        "      <td>   male</td>\n",
        "      <td> 22</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>        A/5 21171</td>\n",
        "      <td>  7.2500</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
        "      <td> female</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>         PC 17599</td>\n",
        "      <td> 71.2833</td>\n",
        "      <td>  C85</td>\n",
        "      <td> C</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td>                            Heikkinen, Miss. Laina</td>\n",
        "      <td> female</td>\n",
        "      <td> 26</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> STON/O2. 3101282</td>\n",
        "      <td>  7.9250</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td>      Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
        "      <td> female</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>           113803</td>\n",
        "      <td> 53.1000</td>\n",
        "      <td> C123</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                          Allen, Mr. William Henry</td>\n",
        "      <td>   male</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>           373450</td>\n",
        "      <td>  8.0500</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "   survived  pclass                                               name  \\\n",
        "0         0       3                            Braund, Mr. Owen Harris   \n",
        "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
        "2         1       3                             Heikkinen, Miss. Laina   \n",
        "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
        "4         0       3                           Allen, Mr. William Henry   \n",
        "\n",
        "      sex  age  sibsp  parch            ticket     fare cabin embarked  \n",
        "0    male   22      1      0         A/5 21171   7.2500   NaN        S  \n",
        "1  female   38      1      0          PC 17599  71.2833   C85        C  \n",
        "2  female   26      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
        "3  female   35      1      0            113803  53.1000  C123        S  \n",
        "4    male   35      0      0            373450   8.0500   NaN        S  "
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_names = titanic.columns[1:]\n",
      "print feature_names\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'pclass', u'name', u'sex', u'age', u'sibsp', u'parch', u'ticket', u'fare', u'cabin', u'embarked'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Keep only class (1st,2nd,3rd), age (float), and sex (masc, fem)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# we keep the class, the age and the sex\n",
      "titanic_X = titanic[['pclass', 'age', 'sex']]\n",
      "feature_names = feature_names[[1, 4, 3]]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print feature_names\n",
      "print titanic_X.iloc[12], titanic_y[12]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'name', u'sibsp', u'age'], dtype='object')\n",
        "pclass       3\n",
        "age         20\n",
        "sex       male\n",
        "Name: 12, dtype: object 0\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Solve missing values ('NA') for the 'age' feature. Solution: use the mean value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We have missing values for age\n",
      "# Assign the mean value\n",
      "ages = titanic_X.age\n",
      "mean_age = titanic_X[titanic.age.notnull()].age.mean()\n",
      "titanic_X.age.fillna(mean_age, inplace=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:5: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print feature_names\n",
      "print titanic_X.iloc[5], titanic_y[5]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'name', u'sibsp', u'age'], dtype='object')\n",
        "pclass           3\n",
        "age       29.69912\n",
        "sex           male\n",
        "Name: 5, dtype: object 0\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Class and sex are categorical classes. Sex can be converted to a binary value (0=female,1=male):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Encode sex \n",
      "titanic_X['is_male'] = titanic_X['sex'].apply(lambda x: 1 if x =='male' else 0)\n",
      "\n",
      "print titanic_X[['is_male','sex']].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   is_male     sex\n",
        "0        1    male\n",
        "1        0  female\n",
        "2        0  female\n",
        "3        0  female\n",
        "4        1    male\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print feature_names\n",
      "print titanic_X.iloc[5], titanic_y[5]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'name', u'sibsp', u'age'], dtype='object')\n",
        "pclass            3\n",
        "age        29.69912\n",
        "sex            male\n",
        "is_male           1\n",
        "Name: 5, dtype: object 0\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we have to convert the class. Since we have three different classes, we cannot convert to binary values (and using 0/1/2 values would imply an order, something we do not want). We use OneHotEncoder to get three different attributes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pclasses = pd.get_dummies(titanic_X.pclass)\n",
      "titanic_X = titanic_X.join(pclasses)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print titanic_X.iloc[5], titanic_y[5]\n",
      "titanic_X.drop('sex', axis=1, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pclass            3\n",
        "age        29.69912\n",
        "sex            male\n",
        "is_male           1\n",
        "1                 0\n",
        "2                 0\n",
        "3                 1\n",
        "Name: 5, dtype: object 0\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Separate training and test sets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(titanic_X, titanic_y, test_size=0.25, random_state=33)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Decision Trees"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fit a decision tree with the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import tree\n",
      "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5)\n",
      "clf = clf.fit(X_train,y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Measure Accuracy, precision, recall, f1 in the training set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "def measure_performance(X,y,clf, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
      "    y_pred=clf.predict(X)   \n",
      "    if show_accuracy:\n",
      "        print \"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y,y_pred)),\"\\n\"\n",
      "\n",
      "    if show_classification_report:\n",
      "        print \"Classification report\"\n",
      "        print metrics.classification_report(y,y_pred),\"\\n\"\n",
      "        \n",
      "    if show_confusion_matrix:\n",
      "        print \"Confusion matrix\"\n",
      "        print metrics.confusion_matrix(y,y_pred),\"\\n\"\n",
      "        \n",
      "measure_performance(X_train,y_train,clf, show_classification_report=True, show_confusion_matrix=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:0.802 \n",
        "\n",
        "Classification report\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.82      0.87      0.85       415\n",
        "          1       0.76      0.69      0.73       253\n",
        "\n",
        "avg / total       0.80      0.80      0.80       668\n",
        "\n",
        "\n",
        "Confusion matrix\n",
        "[[361  54]\n",
        " [ 78 175]] \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Perform leave-one-out cross validation to better measure performance, reducing variance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score, LeaveOneOut\n",
      "from sklearn import metrics\n",
      "from scipy.stats import sem\n",
      "\n",
      "def loo_cv(X_train,y_train,clf):\n",
      "    # Perform Leave-One-Out cross validation\n",
      "    # We are preforming 1313 classifications!\n",
      "    loo = LeaveOneOut(X_train[:].shape[0])\n",
      "    scores=np.zeros(X_train[:].shape[0])\n",
      "    for train_index,test_index in loo:\n",
      "        X_train_cv, X_test_cv= X_train[train_index], X_train[test_index]\n",
      "        y_train_cv, y_test_cv= y_train[train_index], y_train[test_index]\n",
      "        clf = clf.fit(X_train_cv,y_train_cv)\n",
      "        y_pred=clf.predict(X_test_cv)\n",
      "        scores[test_index]=metrics.accuracy_score(y_test_cv.astype(int), y_pred.astype(int))\n",
      "    print (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(np.mean(scores), sem(scores))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "LeaveOneOut?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loo_cv(X_train, y_train,clf)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mean score: 0.802 (+/-0.015)\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Try to improve performance using Random Forests"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "clf = RandomForestClassifier(n_estimators=10,random_state=33)\n",
      "clf = clf.fit(X_train,y_train)\n",
      "loo_cv(X_train,y_train,clf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To evaluate performance on future data, evaluate on the training set and test on the evaluation set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Attempt 1\n",
      "clf_dt=tree.DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5)\n",
      "clf_dt.fit(X_train,y_train)\n",
      "measure_performance(X_test,y_test,clf_dt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree.DecisionTreeClassifier?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Attempt 2\n",
      "clf_dt=tree.DecisionTreeClassifier(criterion='gini', max_depth=3,min_samples_leaf=20)\n",
      "clf_dt.fit(X_train,y_train)\n",
      "measure_performance(X_test,y_test,clf_dt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "A New Measure: the ROC and Area Under a Curve (AUC)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One way we can score a binary classification is by plotting the reciever operating characteristic and determining the value of the area under curve (AUC). Like above, our goal is to see an AUC as close to 1 as possible."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Syntax for roc_curve is roc_curve(actual, prediction, [pos_label if it's not 1])\n",
      "predictions = [p[1] for p in clf_dt.predict_proba(X_train)]\n",
      "fpr_p, tpr_p, thresholds_p = metrics.roc_curve(y_train,predictions)\n",
      "\n",
      "fig = plt.figure()\n",
      "fig.set_figwidth(10)\n",
      "fig.suptitle('AUC for Decision Tree Classifier Predicting Titanic Survivors')\n",
      "\n",
      "ax1 = plt.subplot(1, 2, 1)\n",
      "ax1.set_xlabel('false positive rate')\n",
      "ax1.set_ylabel('true positive rate')\n",
      "ax1.plot(fpr_p, tpr_p)\n",
      "\n",
      "fpr, tpr, thresholds = metrics.roc_curve(y_train,clf_dt.predict(X_train))\n",
      "ax2 = plt.subplot(1, 2, 2)\n",
      "ax2.set_xlabel('false positive rate')\n",
      "ax2.set_ylabel('true positive rate')\n",
      "ax2.plot(fpr, tpr)\n",
      "\n",
      "\n",
      "print \"False-positive rate:\", fpr\n",
      "print \"True-positive rate: \", tpr\n",
      "print \"Thresholds:         \", thresholds\n",
      "\n",
      "print fig"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "\n",
      "random.seed( 100 )\n",
      "print \"Random number with seed 10 : \", random.random()\n",
      "\n",
      "# It will generate same random number\n",
      "random.seed( 100 )\n",
      "print \"Random number with seed 10 : \", random.random()\n",
      "\n",
      "# It will generate same random number\n",
      "random.seed( 100 )\n",
      "print \"Random number with seed 10 : \", random.random()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Reading this**\n",
      "\n",
      "When we consider a positive (1) instance matching a postive (1) test, then that's considered a *true positive*; otherwise, it is considered a *false negative*. If the instance is a negative and it is classified as negative, we consider that a *true negative*; otherwise, a *false positive*. \n",
      "\n",
      "The True Positive Rate (tpr) is calculated using true positives / all positives, while the False Positive Rate (fpr) is calculated using false negatives / all negatives.\n",
      "\n",
      "We can find *sensitivity* as (True Negatives) / (False Positives + True Negatives).\n",
      "\n",
      "The goal for an AUC curve is to be as close to point(0, 1) as possible, which means 0 false positive, and all true positives. \n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Assignment"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Continue plugging away at the titanic data set to see if you can come up with a **better** predictor than what we built above using either DT, RF, or naive bayes!\n",
      "\n",
      "You will want to spend **MOST** of your time continuing to manipulate the data set, creating new features, and understanding the relationship between these features and how they contribute to predicting the \"survived\" data.\n",
      "\n",
      "Please work with a partner and pair program."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}